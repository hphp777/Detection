{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "yolov3_train_coco.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hphp777/Detection/blob/main/YOLO/dirrectory_setting_yolov3_train_coco.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPvjfCWE2KFj"
      },
      "source": [
        "### Ultralytics Yolo v3 설치"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XorGnZsFplS3"
      },
      "source": [
        "기본적으로 시간이 제일 많이 걸리는 부분이 데이터셋을 페키지가 원하는 형태로 가공하는것, 그리고 config를 설정하는 것이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "I_Ua0GO8Sa5s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3576c679-78ab-4cbd-b601-917d7bd9eecc"
      },
      "source": [
        "!git clone https://github.com/ultralytics/yolov3\n",
        "!cd yolov3;pip install -qr requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'yolov3'...\n",
            "remote: Enumerating objects: 9862, done.\u001b[K\n",
            "remote: Total 9862 (delta 0), reused 0 (delta 0), pack-reused 9862\u001b[K\n",
            "Receiving objects: 100% (9862/9862), 9.19 MiB | 17.33 MiB/s, done.\n",
            "Resolving deltas: 100% (6666/6666), done.\n",
            "\u001b[K     |████████████████████████████████| 636 kB 13.0 MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "b1xaZlnSSa53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53bb092a-0e1e-4ded-a9b5-9680ad06d020"
      },
      "source": [
        "import torch\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "\n",
        "clear_output()\n",
        "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setup complete. Using torch 1.9.0+cu102 (Tesla K80)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wuNsf3fL2kD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b0b06a0-188a-4563-8c82-4696d3d0ca7a"
      },
      "source": [
        "# yaml은 데이터셋에 관한 것. cfg, data, hyp가 이러한 데이터포멧을 필요로 한다.\n",
        "# 이 경우 경로가 안적혀있으니까 yolov3밑에 data폴더에 들어가 있음\n",
        "# xml -> jason -> yaml 로 발전해 옴\n",
        "# coco128은 기본적으로 들어있는 데이터 셋. 써주기만 하면 자동으로 다운로드 받음\n",
        "# content/coco128/images/train...\n",
        "# 학습이 끝나면 학습된 weight를 저장한다.\n",
        "%cd yolov3\n",
        "!python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov3.pt --nosave "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/yolov3\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov3 ✅\n",
            "YOLOv3 🚀 v9.5.0-13-g1be3170 torch 1.9.0+cu102 CUDA:0 (Tesla K80, 11441.1875MB)\n",
            "\n",
            "Namespace(adam=False, artifact_alias='latest', batch_size=16, bbox_interval=-1, bucket='', cache_images=False, cfg='', data='./data/coco128.yaml', device='', entity=None, epochs=3, evolve=False, exist_ok=False, global_rank=-1, hyp='data/hyp.scratch.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='exp', noautoanchor=False, nosave=True, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/exp', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=16, upload_dataset=False, weights='yolov3.pt', workers=8, world_size=1)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOv3 logging with 'pip install wandb' (recommended)\n",
            "Downloading https://github.com/ultralytics/yolov3/releases/download/v9.5.0/yolov3.pt to yolov3.pt...\n",
            "100% 118M/118M [00:06<00:00, 20.5MB/s]\n",
            "\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     20672  models.common.Bottleneck                [64, 64]                      \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    164608  models.common.Bottleneck                [128, 128]                    \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  8   2627584  models.common.Bottleneck                [256, 256]                    \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  8  10498048  models.common.Bottleneck                [512, 512]                    \n",
            "  9                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            " 10                -1  4  20983808  models.common.Bottleneck                [1024, 1024]                  \n",
            " 11                -1  1   5245952  models.common.Bottleneck                [1024, 1024, False]           \n",
            " 12                -1  1    525312  models.common.Conv                      [1024, 512, [1, 1]]           \n",
            " 13                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 14                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 15                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 16                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 18           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
            " 19                -1  1   1377792  models.common.Bottleneck                [768, 512, False]             \n",
            " 20                -1  1   1312256  models.common.Bottleneck                [512, 512, False]             \n",
            " 21                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 22                -1  1   1180672  models.common.Conv                      [256, 512, 3, 1]              \n",
            " 23                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 24                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 25           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 26                -1  1    344832  models.common.Bottleneck                [384, 256, False]             \n",
            " 27                -1  2    656896  models.common.Bottleneck                [256, 256, False]             \n",
            " 28      [27, 22, 15]  1    457725  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
            "Model Summary: 333 layers, 61949149 parameters, 61949149 gradients, 156.4 GFLOPS\n",
            "\n",
            "Transferred 440/440 items from yolov3.pt\n",
            "\n",
            "WARNING: Dataset not found, nonexistent paths: ['/content/coco128/images/train2017']\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v1.0/coco128.zip ...\n",
            "100% 6.66M/6.66M [00:00<00:00, 22.1MB/s]\n",
            "Dataset autodownload success\n",
            "\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 75 .bias, 75 conv.weight, 72 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../coco128/labels/train2017' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:00<00:00, 1738.16it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: ../coco128/labels/train2017.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '../coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:00<?, ?it/s][W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "Plotting labels... \n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '../coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 4.26, Best Possible Recall (BPR) = 0.9946\n",
            "Image sizes 640 train, 640 test\n",
            "Using 2 dataloader workers\n",
            "Logging results to runs/train/exp\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       0/2     8.18G   0.02765   0.02264   0.00522   0.05552       181       640:   0% 0/8 [00:20<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 541, in <module>\n",
            "    train(hyp, opt, device, tb_writer)\n",
            "  File \"train.py\", line 334, in train\n",
            "    tb_writer.add_graph(torch.jit.trace(de_parallel(model), imgs, strict=False), [])  # model graph\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/jit/_trace.py\", line 744, in trace\n",
            "    _module_class,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/jit/_trace.py\", line 959, in trace_module\n",
            "    argument_names,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1039, in _slow_forward\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/yolov3/models/yolo.py\", line 121, in forward\n",
            "    return self.forward_once(x, profile)  # single-scale inference, train\n",
            "  File \"/content/yolov3/models/yolo.py\", line 152, in forward_once\n",
            "    x = m(x)  # run\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1039, in _slow_forward\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\", line 139, in forward\n",
            "    input = module(input)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1039, in _slow_forward\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/yolov3/models/common.py\", line 104, in forward\n",
            "    return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))\n",
            "RuntimeError: CUDA out of memory. Tried to allocate 100.00 MiB (GPU 0; 11.17 GiB total capacity; 10.15 GiB already allocated; 79.81 MiB free; 10.64 GiB reserved in total by PyTorch)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtQd5TmHMgxE"
      },
      "source": [
        "### wandb(weight and bias) 모듈을 설치\n",
        "* 먼저 Weight and Bias 웹사이트에 계정 생성 및 연계 후 train 작업이 필요할 수도 있음."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKc9lL_oKCPJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7b24cc0-22f6-43b9-cfc6-a3cce5f9a224"
      },
      "source": [
        "# 만약 이를 설치하면 train.py는 다르게 동작.\n",
        "# tensorboard의 깃헙화. 시각화를 해줌\n",
        "!pip install wandb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.12.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 4.1 MB/s \n",
            "\u001b[?25hCollecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.3.1-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 51.8 MB/s \n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.1-py3-none-any.whl (7.5 kB)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.18-py3-none-any.whl (170 kB)\n",
            "\u001b[K     |████████████████████████████████| 170 kB 56.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.1)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading configparser-5.0.2-py3-none-any.whl (19 kB)\n",
            "Collecting subprocess32>=3.5.3\n",
            "  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 6.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.7-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.0 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.7.4.3)\n",
            "Collecting smmap<5,>=3.0.1\n",
            "  Downloading smmap-4.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Building wheels for collected packages: subprocess32, pathtools\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=6a6c61280a55501aa999bfd0d560ca99ee427893bd95bda13986334f40b5a2aa\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=e1ca03f8cefda7521c4c9caf22581124c842208085e8db771e8ecb5e376725b0\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built subprocess32 pathtools\n",
            "Installing collected packages: smmap, gitdb, subprocess32, shortuuid, sentry-sdk, pathtools, GitPython, docker-pycreds, configparser, wandb\n",
            "Successfully installed GitPython-3.1.18 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.7 pathtools-0.1.2 sentry-sdk-1.3.1 shortuuid-1.0.1 smmap-4.0.0 subprocess32-3.5.4 wandb-0.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T2Hcsh1R5iB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da720e4d-1dad-432f-e586-982e2950db1e"
      },
      "source": [
        "%cd /content\n",
        "%cd yolov3\n",
        "!python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov3.pt --nosave --cache"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content/yolov3\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov3 ✅\n",
            "YOLOv3 🚀 v9.5.0-13-g1be3170 torch 1.9.0+cu102 CUDA:0 (Tesla K80, 11441.1875MB)\n",
            "\n",
            "Namespace(adam=False, artifact_alias='latest', batch_size=16, bbox_interval=-1, bucket='', cache_images=True, cfg='', data='./data/coco128.yaml', device='', entity=None, epochs=3, evolve=False, exist_ok=False, global_rank=-1, hyp='data/hyp.scratch.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='exp', noautoanchor=False, nosave=True, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/exp3', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=16, upload_dataset=False, weights='yolov3.pt', workers=8, world_size=1)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Don't visualize my results'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m `resume` will be ignored since W&B syncing is set to `offline`. Starting a new run with run id 2o6m408r.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to `offline` in this directory.  Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     20672  models.common.Bottleneck                [64, 64]                      \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    164608  models.common.Bottleneck                [128, 128]                    \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  8   2627584  models.common.Bottleneck                [256, 256]                    \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  8  10498048  models.common.Bottleneck                [512, 512]                    \n",
            "  9                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            " 10                -1  4  20983808  models.common.Bottleneck                [1024, 1024]                  \n",
            " 11                -1  1   5245952  models.common.Bottleneck                [1024, 1024, False]           \n",
            " 12                -1  1    525312  models.common.Conv                      [1024, 512, [1, 1]]           \n",
            " 13                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 14                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 15                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 16                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 18           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
            " 19                -1  1   1377792  models.common.Bottleneck                [768, 512, False]             \n",
            " 20                -1  1   1312256  models.common.Bottleneck                [512, 512, False]             \n",
            " 21                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 22                -1  1   1180672  models.common.Conv                      [256, 512, 3, 1]              \n",
            " 23                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 24                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 25           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 26                -1  1    344832  models.common.Bottleneck                [384, 256, False]             \n",
            " 27                -1  2    656896  models.common.Bottleneck                [256, 256, False]             \n",
            " 28      [27, 22, 15]  1    457725  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
            "Model Summary: 333 layers, 61949149 parameters, 61949149 gradients, 156.4 GFLOPS\n",
            "\n",
            "Transferred 440/440 items from yolov3.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 75 .bias, 75 conv.weight, 72 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:00<?, ?it/s]\n",
            "  0% 0/128 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB):  11% 14/128 [00:00<00:00, 134.89it/s]\u001b[A\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB):  55% 71/128 [00:00<00:00, 233.20it/s]\u001b[A\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB): 100% 128/128 [00:00<00:00, 259.81it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '../coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '../coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB):  11% 14/128 [00:00<00:00, 117.80it/s]\u001b[A\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB):  29% 37/128 [00:00<00:00, 179.03it/s]\u001b[A\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB):  44% 56/128 [00:00<00:00, 163.23it/s]\u001b[A\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB):  60% 77/128 [00:00<00:00, 175.54it/s]\u001b[A\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB):  74% 95/128 [00:00<00:00, 135.22it/s]\u001b[A\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB): 100% 128/128 [00:00<00:00, 166.94it/s]\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "Plotting labels... \n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 4.26, Best Possible Recall (BPR) = 0.9946\n",
            "Image sizes 640 train, 640 test\n",
            "Using 2 dataloader workers\n",
            "Logging results to runs/train/exp3\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       0/2     8.18G   0.02765   0.02264   0.00522   0.05552       181       640:   0% 0/8 [00:20<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 541, in <module>\n",
            "    train(hyp, opt, device, tb_writer)\n",
            "  File \"train.py\", line 334, in train\n",
            "    tb_writer.add_graph(torch.jit.trace(de_parallel(model), imgs, strict=False), [])  # model graph\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/jit/_trace.py\", line 744, in trace\n",
            "    _module_class,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/jit/_trace.py\", line 959, in trace_module\n",
            "    argument_names,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1039, in _slow_forward\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/yolov3/models/yolo.py\", line 121, in forward\n",
            "    return self.forward_once(x, profile)  # single-scale inference, train\n",
            "  File \"/content/yolov3/models/yolo.py\", line 152, in forward_once\n",
            "    x = m(x)  # run\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1039, in _slow_forward\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\", line 139, in forward\n",
            "    input = module(input)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1039, in _slow_forward\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/yolov3/models/common.py\", line 104, in forward\n",
            "    return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))\n",
            "RuntimeError: CUDA out of memory. Tried to allocate 100.00 MiB (GPU 0; 11.17 GiB total capacity; 10.15 GiB already allocated; 79.81 MiB free; 10.64 GiB reserved in total by PyTorch)\n",
            "Images sizes do not match. This will causes images to be display incorrectly in the UI.\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 451\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 1. \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: /content/yolov3/wandb/offline-run-20210821_080337-2o6m408r/logs/debug.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: /content/yolov3/wandb/offline-run-20210821_080337-2o6m408r/logs/debug-internal.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     _runtime 34\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   _timestamp 1629533051\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        _step 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     _runtime ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   _timestamp ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        _step ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mwandb sync /content/yolov3/wandb/offline-run-20210821_080337-2o6m408r\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNIrsZHI0_tz"
      },
      "source": [
        "### Dataset Config와 Weight 파일의 상대 경로, 절대 경로\n",
        "* train.py의 data option값으로 Dataset config yaml 파일을 지정할 수 있으며, 파일명만 입력할 경우는 yolov3/data 디렉토리 아래에서 해당 파일을 찾음. 절대 경로로 입력할 경우 해당 경로에서 찾음. \n",
        "* weights option의 경우 파일명만 입력할 경우 yolov3 디렉토리에서 해당 파일을 찾음. 해당 파일이 없을 경우 자동으로 해당 파일을 https://github.com/ultralytics/yolov3/releases 에서 Download 함. 절대 경로를 입력한 경우 해당 경로에서 파일을 찾되 파일이 없으면 해당 경로로 자동 Download함. \n",
        "* weights 파일은 yolov3.pt, yolov3-tiny.pt, yolov3-spp.pt 그러면 이 유형에 맞는 pt파일을 (만약 명시하지 않은 경우)자동으로 다운로드 할 수 있음."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLfxF4g_3Zh-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bf92715-05e8-4d5e-a051-1c4fcac1a7ce"
      },
      "source": [
        "%cd /content"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wPnWKNXMSa5_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ab200b2-810a-49fd-d81e-1d3d319e8a24"
      },
      "source": [
        "# nosave option은 맨 마지막 weight만 save. \n",
        "# cache는 읽은 이미지를 cashing하는 것\n",
        "# weight의 절대경로에 해당 파일이 없으면 자동으로 다운로드\n",
        "#!cd yolov3; python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov3.pt --nosave --cache\n",
        "#!cd yolov3; python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights '' --cfg yolov3.yaml --nosave --cache\n",
        "!cd yolov3; python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov3-tiny.pt --nosave --cache\n",
        "#!cd yolov3;python train.py --img 640 --batch 16 --epochs 3 --data /content/coco128/coco128.yaml --weights /content/coco128/yolov3-tiny.pt --nosave --cache\n",
        "#!cd yolov3;python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov3-spp.pt --nosave --cache"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov3 ✅\n",
            "YOLOv3 🚀 v9.5.0-13-g1be3170 torch 1.9.0+cu102 CUDA:0 (Tesla K80, 11441.1875MB)\n",
            "\n",
            "Namespace(adam=False, artifact_alias='latest', batch_size=16, bbox_interval=-1, bucket='', cache_images=True, cfg='', data='./data/coco128.yaml', device='', entity=None, epochs=3, evolve=False, exist_ok=False, global_rank=-1, hyp='data/hyp.scratch.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='exp', noautoanchor=False, nosave=True, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/exp2', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=16, upload_dataset=False, weights='yolov3-tiny.pt', workers=8, world_size=1)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOv3 logging with 'pip install wandb' (recommended)\n",
            "Downloading https://github.com/ultralytics/yolov3/releases/download/v9.5.0/yolov3-tiny.pt to yolov3-tiny.pt...\n",
            "100% 16.9M/16.9M [00:00<00:00, 66.0MB/s]\n",
            "\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       464  models.common.Conv                      [3, 16, 3, 1]                 \n",
            "  1                -1  1         0  torch.nn.modules.pooling.MaxPool2d      [2, 2, 0]                     \n",
            "  2                -1  1      4672  models.common.Conv                      [16, 32, 3, 1]                \n",
            "  3                -1  1         0  torch.nn.modules.pooling.MaxPool2d      [2, 2, 0]                     \n",
            "  4                -1  1     18560  models.common.Conv                      [32, 64, 3, 1]                \n",
            "  5                -1  1         0  torch.nn.modules.pooling.MaxPool2d      [2, 2, 0]                     \n",
            "  6                -1  1     73984  models.common.Conv                      [64, 128, 3, 1]               \n",
            "  7                -1  1         0  torch.nn.modules.pooling.MaxPool2d      [2, 2, 0]                     \n",
            "  8                -1  1    295424  models.common.Conv                      [128, 256, 3, 1]              \n",
            "  9                -1  1         0  torch.nn.modules.pooling.MaxPool2d      [2, 2, 0]                     \n",
            " 10                -1  1   1180672  models.common.Conv                      [256, 512, 3, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.padding.ZeroPad2d      [[0, 1, 0, 1]]                \n",
            " 12                -1  1         0  torch.nn.modules.pooling.MaxPool2d      [2, 1, 0]                     \n",
            " 13                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 14                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 15                -1  1   1180672  models.common.Conv                      [256, 512, 3, 1]              \n",
            " 16                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 18           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
            " 19                -1  1    885248  models.common.Conv                      [384, 256, 3, 1]              \n",
            " 20          [19, 15]  1    196350  models.yolo.Detect                      [80, [[10, 14, 23, 27, 37, 58], [81, 82, 135, 169, 344, 319]], [256, 512]]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "Model Summary: 59 layers, 8852366 parameters, 8852366 gradients, 13.3 GFLOPS\n",
            "\n",
            "Transferred 72/72 items from yolov3-tiny.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 13 .bias, 13 conv.weight, 11 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB): 100% 128/128 [00:00<00:00, 256.91it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '../coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB): 100% 128/128 [00:00<00:00, 183.51it/s]\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "Plotting labels... \n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 2.85, Best Possible Recall (BPR) = 0.9903\n",
            "Image sizes 640 train, 640 test\n",
            "Using 2 dataloader workers\n",
            "Logging results to runs/train/exp2\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       0/2     2.75G   0.05195   0.07895   0.02405     0.155       184       640:   0% 0/8 [00:06<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/jit/_trace.py:730: UserWarning: The input to trace is already a ScriptModule, tracing it is a no-op. Returning the object as is.\n",
            "  \"The input to trace is already a ScriptModule, tracing it is a no-op. Returning the object as is.\"\n",
            "       0/2     7.33G   0.05314   0.09579   0.02647    0.1754       199       640: 100% 8/8 [00:13<00:00,  1.70s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:14<00:00,  3.52s/it]\n",
            "                 all         128         929       0.555       0.358       0.428       0.221\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       1/2     6.32G   0.05206   0.08904   0.02672    0.1678       130       640: 100% 8/8 [00:03<00:00,  2.63it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:01<00:00,  2.43it/s]\n",
            "                 all         128         929       0.552        0.36       0.425       0.224\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       2/2     6.32G   0.05491   0.09181   0.02641    0.1731       163       640: 100% 8/8 [00:03<00:00,  2.64it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.09it/s]\n",
            "                 all         128         929       0.567       0.366        0.43       0.225\n",
            "3 epochs completed in 0.013 hours.\n",
            "\n",
            "Optimizer stripped from runs/train/exp2/weights/last.pt, 17.8MB\n",
            "Optimizer stripped from runs/train/exp2/weights/best.pt, 17.8MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZSXORZdEmvc"
      },
      "source": [
        "!cp /content/yolov3/data/coco128.yaml /content/coco128/coco128.yaml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rf1hUSV6Myw9"
      },
      "source": [
        "### COCO128 데이터 디렉토리를 변경후 학습 수행\n",
        "* /content/data 아래에 coco128 데이터 download 후 unzip\n",
        "* coco128 디렉토리가 변경되었으므로 coco128.yaml 데이터도 변경 적용. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wz37RavwxYE1"
      },
      "source": [
        "# 기존에 기본으로 제공되던 데이터 셋 말고 새로 데이터셋을 다운받아서 train을 적용시켜본다. \n",
        "%cd /content\n",
        "!rm -rf /content/coco128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "guG3eNgXSa56"
      },
      "source": [
        "# /content 디렉토리에 coco128.zip을 download하고 tmp.zip으로 이름 변경 후 압축 해제. \n",
        "torch.hub.download_url_to_file('https://github.com/ultralytics/yolov5/releases/download/v1.0/coco128.zip', 'tmp.zip')\n",
        "!unzip -q tmp.zip -d ./ && rm tmp.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GD-azX0i2m-Y"
      },
      "source": [
        "# /content/data 디렉토리에 coco128.zip을 download하고 압축 해제\n",
        "!mkdir /content/data\n",
        "!wget -O /content/data/coco128.zip https://github.com/ultralytics/yolov5/releases/download/v1.0/coco128.zip\n",
        "!cd /content/data; unzip coco128.zip "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "b4hTenv2Sa59"
      },
      "source": [
        "!wget -O /content/data/coco128/coco128_renew.yaml https://raw.githubusercontent.com/chulminkw/DLCV/master/data/util/coco128_renew.yaml\n",
        "!cat /content/data/coco128/coco128_renew.yaml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZkk2f09xWDT"
      },
      "source": [
        "# yaml파일 안에 train, val 이미지 폴더의 경로가 포함됨. 그리고 그와 대응되는 경로에 annotation이 있음. label디렉토리는 자동으로 찾는것\n",
        "!cd /content/yolov3; python train.py --img 640 --batch 16 --epochs 3 --data /content/data/coco128/coco128_renew.yaml --weights yolov3.pt --nosave --cache"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMrSquxNMDre"
      },
      "source": [
        "### labels 디렉토리명을 변경하고 수행. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r047cg90Sa6P"
      },
      "source": [
        "!mv /content/data/coco128/labels /content/data/coco128/labels_chg #레이블 폴더의 경로 변경"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ef12IcJkLtBY"
      },
      "source": [
        "!cd /content/yolov3; python train.py --img 640 --batch 16 --epochs 3 --data /content/data/coco128/coco128_renew.yaml --weights yolov3.pt --nosave --cache # 레이블 폴더를 못찾음"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLkIb95lL_Tz"
      },
      "source": [
        "# 다시 원복후 학습\n",
        "!mv /content/data/coco128/labels_chg /content/data/coco128/labels \n",
        "!cd /content/yolov3; python train.py --img 640 --batch 16 --epochs 3 --data /content/data/coco128/coco128_renew.yaml --weights yolov3.pt --nosave --cache"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMCIGcG0Mp4c"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}